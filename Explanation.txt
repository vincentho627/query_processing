Initially, we implemented the sorting of relations using merge sort. However, in our implementation, we had to continually create temporary vectors to store the intermediate results, which meant that many CPU cycles were wasted initialising and destroying these vectors. This was further confirmed when we used Intel's Advisor to try and diagnose which function calls were taking up the most time. Eventually, we moved to using quicksort as provided by the cstdlib library, which yielded better performance.

The hashJoin function was also flagged out by Intel's Advisor as taking up a significant amount of time to execute. This could be due to the fact that we are using a simple hashing algorithm (just taking the modulo of the input), leading to many hash collisions and time wasted traversing the hashtable to find an empty slot. We experimented with other hashing algorithms, such as CRC32 but found that the time taken to run the hash was more than the time saved by reducing hash collisions. As such, we stuck to using the simple hashing algorithm. 

We also made use of bitwise ANDs to calculate our hashes, since division is expensive in hardware. To do so, we had to calculate the smallest power of 2 larger than the size of the small relation. Through further testing, we also discovered that overallocating the size of the hashtable by 4 led to the best performance. If the hashtable is too small, then there could be a large number of hash collisions, leading to time wasted traversing the hashtable. If the hashtable is too large, then it could possibly not fit in the lower cache levels, which would lead to increased access time during the probing phase, since every access would evict another member of the hashtable, potentially causing cache thrashing.
